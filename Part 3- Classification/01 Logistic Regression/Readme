Assumptions:
1. Dependent variable should be measured on a dichotomous scale
2. One or more independent variables, which can be either continuous (i.e., an interval or ratio variable) or categorical (i.e., an ordinal or nominal variable)
3. Independence of observations, and Dependent variable should have mutually exclusive and exhaustive categories.
4. There needs to be a linear relationship between any continuous independent variables and the logit transformation of the dependent variable

Logistic Regression also drops some of the assumptions of linear regression:
1. Does not assume normality of variables (both DV and IVs).
2. Does not assume linearity between DV and IVs.
3. Does not assume homoscedasticity.
4. Does not assume normal errors.




Eqn:    ln(p/(1-p)) = b0 + b1(X1) +....

Final probability score: '
  1. Probability = e^y/ (1+e^y) ------------- Or if this eqn is multiplied&divied by e^-y, p value will be same as those if sigmoid function
  2. Sigmoid Function: if y= b0 + b1(X1) +.... , then p= 1/(1+(e^-y))  (another representation for the probability value eqn)

Since Logistic Regression is a linear classifier, the decision boundary(optimal line that splits the data) is also linear. 
So there will always be data points on either side that do not belong in split made by the model. 

How to find the Optimal Cut-off?
ANSWER:
1. Plot sensitivity against (1-specificity) to get a ROC diargam.
2. Youden-Index: Detemine the point for which (sensitifity + specificity-1) is maximal. 
3. Another "optimal cut-off" is the value for which the point on the ROC curve has the minimum distance to the upper left corner (where sensitivity=1 and specificity=1). 
